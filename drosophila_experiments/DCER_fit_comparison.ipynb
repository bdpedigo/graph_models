{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a simple DCER to _Drosophila_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the unweighted, symmetrized, loopless right _Drosophila_ larva connectome from Eichler et al (original one) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you will need to be in the graph model branch to run this in GraSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_drosophila_right' from 'graspy.datasets' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-26c7c5d0be35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_drosophila_right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymmetrize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_drosophila_right' from 'graspy.datasets' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from graspy.datasets import load_drosophila_right\n",
    "from graspy.plot import heatmap\n",
    "from graspy.utils import binarize, symmetrize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "adj, labels = load_drosophila_right(return_labels=True)\n",
    "adj = symmetrize(adj, method='avg')\n",
    "adj = binarize(adj)\n",
    "heatmap(adj, inner_hier_labels=labels, transform='simple-nonzero');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting an ER model using the class in GraSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspy.models import EREstimator\n",
    "er = EREstimator(directed=True,loops=False)\n",
    "er.fit(adj)\n",
    "print(f\"ER \\\"p\\\" parameter: {er.p_}\")\n",
    "heatmap(er.p_mat_, inner_hier_labels=labels,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a DCER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{ij} = \\theta_i \\theta_j p$$\n",
    "where $\\theta$ is a length $n$ vector of degree corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature, though derived for *Possion* DCSBMs says to do the following to fit:\n",
    "\n",
    "$k_i$ = degree of node $i$\n",
    "\n",
    "$m$ = sum of edges in graph \n",
    "\n",
    "$\\kappa_{\\tau_i}$ would be sum of edges within block of node $i$ but here we have one block so this is just $m$\n",
    "\n",
    "constrain $\\theta$ to sum to 1\n",
    "\n",
    "$$\\hat{\\theta_i} = \\frac{k_i}{\\kappa_{\\tau_i}} = \\frac{k_i}{m}$$\n",
    "$$\\hat{p} = m$$\n",
    "\n",
    "Note that $p$ here is no longer really a probability in the ER sense\n",
    "\n",
    "$$\\hat{P_{ij}} = \\hat{\\theta_i}\\hat{\\theta_j}\\hat{p} = \\frac{k_i}{m} \\frac{k_j}{m} m = \\frac{k_i k_j}{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially what we have implemented in GraSPy but we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from graspy.models import DCEREstimator\n",
    "dcer = DCEREstimator(directed=True,loops=False)\n",
    "dcer.fit(adj)\n",
    "print(f\"ER \\\"p\\\" parameter: {dcer.p_}\")\n",
    "heatmap(dcer.p_mat_, inner_hier_labels=labels,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_samples(p_mat, graph):\n",
    "        \"\"\"\n",
    "        Compute the weighted log probabilities for each potential edge.\n",
    "\n",
    "        Note that this implicitly assumes the input graph is indexed like the \n",
    "        fit model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph : np.ndarray\n",
    "            input graph\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sample_scores : np.ndarray (size of `graph`)\n",
    "            log-likelihood per potential edge in the graph\n",
    "        \"\"\"\n",
    "        p_mat = p_mat.copy()\n",
    "        successes = np.multiply(p_mat, graph)\n",
    "        failures = np.multiply((1 - p_mat), (1 - graph))\n",
    "        likelihood = successes + failures\n",
    "        return np.log(likelihood)\n",
    "    \n",
    "def score(p_mat, graph):\n",
    "        \"\"\"\n",
    "        Compute the average log-likelihood over each potential edge of the \n",
    "        given graph.\n",
    "\n",
    "        Note that this implicitly assumes the input graph is indexed like the \n",
    "        fit model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph : np.ndarray\n",
    "            input graph\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            sum of log-loglikelihoods for each potential edge in input graph\n",
    "        \"\"\"\n",
    "        return np.sum(score_samples(p_mat, graph))\n",
    "    \n",
    "def score_samples_squishy(p_mat, graph):\n",
    "        \"\"\"\n",
    "        Compute the weighted log probabilities for each potential edge.\n",
    "\n",
    "        Note that this implicitly assumes the input graph is indexed like the \n",
    "        fit model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph : np.ndarray\n",
    "            input graph\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sample_scores : np.ndarray (size of `graph`)\n",
    "            log-likelihood per potential edge in the graph\n",
    "        \"\"\"\n",
    "        p_mat = p_mat.copy()\n",
    "        \n",
    "        # squish the probabilities that are degenerate\n",
    "        c = 1 / graph.size\n",
    "        p_mat[p_mat < c] = c\n",
    "        p_mat[p_mat > 1 - c] = 1 - c\n",
    "        successes = np.multiply(p_mat, graph)\n",
    "        failures = np.multiply((1 - p_mat), (1 - graph))\n",
    "        likelihood = successes + failures\n",
    "        return np.log(likelihood)\n",
    "    \n",
    "def score_squishy(p_mat, graph):\n",
    "        \"\"\"\n",
    "        Compute the average log-likelihood over each potential edge of the \n",
    "        given graph.\n",
    "\n",
    "        Note that this implicitly assumes the input graph is indexed like the \n",
    "        fit model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph : np.ndarray\n",
    "            input graph\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            sum of log-loglikelihoods for each potential edge in input graph\n",
    "        \"\"\"\n",
    "        return np.sum(score_samples_squishy(p_mat, graph))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Fit like in the literature (described above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what the current graspy class does\n",
    "def fit_lit(adj):\n",
    "    n_verts = adj.shape[0]\n",
    "    m = np.sum(adj)\n",
    "    p_mat = np.zeros((n_verts, n_verts))\n",
    "    for i in range(n_verts):\n",
    "        for j in range(n_verts):\n",
    "            dj = np.sum(adj[j,:])\n",
    "            di = np.sum(adj[i,:])\n",
    "            p_mat[i, j] = dj * di / m\n",
    "    p_mat = p_mat - np.diag(np.diag(p_mat))\n",
    "    return p_mat, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mat, p = fit_lit(adj)\n",
    "print(f\"p = {p}\")\n",
    "print(f\"max = {p_mat.max()}\")\n",
    "print(f\"min = {p_mat.min()}\")\n",
    "print(f\"likelihood = {score(p_mat, adj)}\")\n",
    "print(f\"squishy likelihood = {score_squishy(p_mat, adj)}\")\n",
    "heatmap(p_mat, inner_hier_labels=labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: fit using MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to do the same thing to fit $\\hat{\\theta}$ as described above, but fit $\\hat{p}$ by minimizing mean square error between the matrix $\\hat{P}$ and the observed graph:\n",
    "\n",
    "$$\\lVert \\hat{P} - A \\rVert^2_F = \\lVert \\hat{\\theta}\\hat{\\theta}^Tp - A \\rVert^2_F$$\n",
    "\n",
    "formulate like a linear regression: \n",
    "$Y$ is the adjacency matrix (0 or 1)\n",
    "$p$ is a constant that we will fit \n",
    "$T$ is the outer product of $\\hat{\\theta}$ with itself\n",
    "$$Y = p T$$\n",
    "just use linear regression to fit p (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_mse(adj,):\n",
    "    n_verts = adj.shape[0]\n",
    "    p_mat = np.zeros((n_verts, n_verts))\n",
    "    m = adj.sum()\n",
    "    for i in range(n_verts):\n",
    "        for j in range(n_verts):\n",
    "            dj = np.sum(adj[j,:]) / m\n",
    "            di = np.sum(adj[i,:]) / m\n",
    "            p_mat[i, j] = dj * di\n",
    "    lr = LinearRegression(fit_intercept=False)\n",
    "    p_mat = p_mat - np.diag(np.diag(p_mat))\n",
    "    lr.fit(p_mat.ravel()[:,np.newaxis], adj.ravel()[:,np.newaxis])\n",
    "    p = lr.coef_[0,0]\n",
    "    p_mat = p_mat * p\n",
    "    return p_mat, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_mat, p = fit_mse(adj)\n",
    "print(f\"p = {p}\")\n",
    "print(f\"max = {p_mat.max()}\")\n",
    "print(f\"min = {p_mat.min()}\")\n",
    "print(f\"likelihood = {score(p_mat, adj)}\")\n",
    "print(f\"squishy likelihood = {score_squishy(p_mat, adj)}\");\n",
    "heatmap(p_mat, inner_hier_labels=labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit parameter $\\hat{p}$ is very similar to that found with method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: fit MLE kinda?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit $\\hat{\\theta}$ as before\n",
    "Fit $\\hat{p}$ by maximizing the likelihood of observing the graph given the model\n",
    "$$f(A | \\theta, p) = \\prod_{i \\neq j} (\\theta_i \\theta_j p)^{A_{ij}} (1 - \\theta_i \\theta_j p)^{1 - A_{ij}}$$\n",
    "$$\\hat{p} = argmax_p \\prod_{i \\neq j} (\\hat{\\theta_i} \\hat{\\theta_j} p)^{A_{ij}} (1 - \\hat{\\theta_i} \\hat{\\theta_j} p)^{1 - A_{ij}}$$\n",
    "\n",
    "Here I just do that numerically (constrained so that p is in [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def likelihood(c, p_mat, adj):\n",
    "    p_mat = p_mat.copy()\n",
    "    p_mat *= c\n",
    "    lik = score(p_mat, adj)\n",
    "    return -lik\n",
    "\n",
    "def fit_mle(adj,):\n",
    "    n_verts = adj.shape[0]\n",
    "    p_mat = np.zeros((n_verts, n_verts))\n",
    "    m = adj.sum()\n",
    "    for i in range(n_verts):\n",
    "        for j in range(n_verts):\n",
    "            dj = np.sum(adj[j,:]) / m \n",
    "            di = np.sum(adj[i,:]) / m\n",
    "            p_mat[i, j] = dj * di\n",
    "    p_mat = p_mat - np.diag(np.diag(p_mat))\n",
    "    lik = lambda c : likelihood(c, p_mat, adj)\n",
    "    res = minimize_scalar(lik, bounds=(0, 1/p_mat.max()), method=\"Bounded\")\n",
    "    p = res.x\n",
    "    print(f\"Optimized: {res.success}\")\n",
    "    p_mat = p_mat * p\n",
    "    return p_mat, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mat, p = fit_mle(adj)\n",
    "heatmap(p_mat, inner_hier_labels=labels)\n",
    "print(f\"p = {p}\")\n",
    "print(f\"max = {p_mat.max()}\")\n",
    "print(f\"min = {p_mat.min()}\")\n",
    "print(f\"squishy likelihood = {score_squishy(p_mat, adj)}\");\n",
    "print(f\"likelihood = {score(p_mat, adj)}\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likelihood(p_mat):\n",
    "    vals = np.linspace(0.5, 1.5, 50)\n",
    "    outs = []\n",
    "    for i in vals:\n",
    "        out = score(p_mat*i, adj)\n",
    "        outs.append(out)\n",
    "    plt.plot(vals, outs)\n",
    "\n",
    "plot_likelihood(p_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
